# Healthcare RAG API

API backend cho há»‡ thá»‘ng tÆ° váº¥n sá»©c khá»e thÃ´ng minh sá»­ dá»¥ng RAG (Retrieval-Augmented Generation).

## ğŸš€ TÃ­nh nÄƒng

- âœ… **REST API** vá»›i FastAPI
- âœ… **TÃ¬m kiáº¿m ngá»¯ nghÄ©a** vá»›i PhoBERT + HNSW
- âœ… **TÃ­ch há»£p Q&A Database** (60K+ cÃ¢u há»i)
- âœ… **TÃ­ch há»£p Articles** (200K+ bÃ i viáº¿t y táº¿)
- âœ… **Index Caching** - khá»Ÿi Ä‘á»™ng nhanh 96x (5 giÃ¢y vs 8 phÃºt) ğŸš€
- âœ… **Medical Safety Guardrails** - phÃ¡t hiá»‡n tÃ¬nh huá»‘ng kháº©n cáº¥p
- âœ… **LLM Generation** vá»›i Vistral-7B-Chat
- âœ… **CORS** cho web frontend
- âœ… **Auto Documentation** táº¡i `/docs`
- âœ… **GPU/CPU Support** tá»± Ä‘á»™ng

## âš¡ Performance Improvements

**vs Notebook gá»‘c:**
- **Startup time:** 8 phÃºt â†’ 5 giÃ¢y (vá»›i cache enabled) ğŸš€
- **No CLI blocking** - production-ready REST API
- **Environment-based config** - khÃ´ng hard-code paths
- **Emergency detection** - 6 categories vá»›i response Æ°u tiÃªn

Chi tiáº¿t: Xem [FIXES_REPORT.md](FIXES_REPORT.md)

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- Python 3.9+
- RAM: 8GB+ (16GB khuyáº¿n nghá»‹)
- GPU: Optional (CUDA 11.8+ náº¿u cÃ³)
- Disk: 5GB+ cho models + 2GB cho cache

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. Clone repository

```bash
git clone <your-repo>
cd Healthcare_Recommendation_System
```

### 2. Táº¡o virtual environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 4. Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

```bash
# Copy file .env.example
cp .env.example .env

# Chá»‰nh sá»­a .env theo nhu cáº§u
notepad .env  # Windows
nano .env     # Linux/Mac
```

**Recommended settings:**
```env
# Enable cache Ä‘á»ƒ khá»Ÿi Ä‘á»™ng nhanh (5s vs 8 phÃºt)
ENABLE_CACHE=1

# Force CPU náº¿u khÃ´ng cÃ³ GPU
FORCE_CPU=0

# Sample size (tÄƒng = chÃ­nh xÃ¡c hÆ¡n, cháº­m hÆ¡n)
SAMPLE_SIZE=5000
```

### 5. Äáº£m báº£o dá»¯ liá»‡u cÃ³ sáºµn

Kiá»ƒm tra cÃ¡c file trong thÆ° má»¥c `data/`:
- `QAs.csv`
- `articles.csv`
- `rag_gold_eval_semantic.json` (optional)

## ğŸš€ Cháº¡y API

### Development mode

```bash
# Láº§n Ä‘áº§u: ~8 phÃºt (build + cache indices)
# Láº§n sau: ~5 giÃ¢y (load tá»« cache) ğŸš€
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

### Production mode

```bash
# Vá»›i gunicorn (Linux/Mac)
gunicorn api.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000

# Vá»›i uvicorn (Windows)
uvicorn api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

**Performance tips:**
- âœ… Äá»ƒ `ENABLE_CACHE=1` (recommended)
- âœ… Clear cache náº¿u data thay Ä‘á»•i: `rm -rf cache/`
- âœ… DÃ¹ng GPU náº¿u cÃ³ (tÄƒng tá»‘c 3-5x)

API sáº½ cháº¡y táº¡i: `http://localhost:8000`

## ğŸ“š API Endpoints

### 1. Health Check
```http
GET /api/health
```

**Response:**
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "models_loaded": true,
  "gpu_available": true
}
```

### 2. Chat (Há»i Ä‘Ã¡p)
```http
POST /api/chat
Content-Type: application/json

{
  "query": "BÃ© 2 tuá»•i sá»‘t 38.5 Ä‘á»™, tÃ´i pháº£i lÃ m gÃ¬?",
  "include_sources": true
}
```

**Response:**
```json
{
  "answer": "ChÃ o báº¡n, dá»±a trÃªn thÃ´ng tin y táº¿...",
  "specialty": "Nhi Khoa",
  "confidence": 0.85,
  "sources": [
    {
      "type": "qa",
      "question": "BÃ© tÃ´i sá»‘t cao pháº£i lÃ m sao?",
      "score": 0.89,
      "snippet": "Sá»‘t 38.5Â°C á»Ÿ tráº» nhá»..."
    }
  ]
}
```

### 3. Danh sÃ¡ch chuyÃªn khoa
```http
GET /api/specialties
```

**Response:**
```json
{
  "specialties": [
    {"name": "Nhi Khoa", "count": 15234},
    {"name": "Tim Máº¡ch", "count": 8765}
  ],
  "total": 25
}
```

### 4. Thá»‘ng kÃª há»‡ thá»‘ng
```http
GET /api/stats
```

## ğŸ§ª Testing

### Sá»­ dá»¥ng curl

```bash
# Health check
curl http://localhost:8000/api/health

# Chat
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "BÃ© sá»‘t 38 Ä‘á»™ pháº£i lÃ m sao?"}'
```

### Sá»­ dá»¥ng Python

```python
import requests

# Chat request
response = requests.post(
    "http://localhost:8000/api/chat",
    json={
        "query": "BÃ© 2 tuá»•i sá»‘t 38.5 Ä‘á»™, tÃ´i pháº£i lÃ m gÃ¬?",
        "include_sources": True
    }
)

print(response.json())
```

### Sá»­ dá»¥ng Swagger UI

Truy cáº­p: `http://localhost:8000/docs`

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
Healthcare_Recommendation_System/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py           # FastAPI application
â”‚   â”œâ”€â”€ models.py         # Pydantic models
â”‚   â”œâ”€â”€ rag_engine.py     # Core RAG logic
â”‚   â””â”€â”€ config.py         # Configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ QAs.csv
â”‚   â”œâ”€â”€ articles.csv
â”‚   â””â”€â”€ rag_gold_eval_semantic.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README_API.md
```

## âš™ï¸ Configuration

CÃ¡c biáº¿n mÃ´i trÆ°á»ng trong `.env`:

| Biáº¿n | MÃ´ táº£ | Máº·c Ä‘á»‹nh |
|------|-------|----------|
| `FORCE_CPU` | Báº¯t buá»™c dÃ¹ng CPU | `0` |
| `SAMPLE_SIZE` | Sá»‘ lÆ°á»£ng máº«u load | `5000` |
| `TOP_K_QA` | Sá»‘ Q&A tráº£ vá» | `5` |
| `TOP_K_ARTICLES` | Sá»‘ bÃ i viáº¿t tráº£ vá» | `1` |
| `CORS_ORIGINS` | Allowed origins | `http://localhost:3000` |

## ğŸ³ Docker Deployment (Optional)

### Táº¡o Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Build vÃ  Run

```bash
docker build -t healthcare-rag-api .
docker run -p 8000:8000 -v $(pwd)/data:/app/data healthcare-rag-api
```

## ğŸ“Š Performance

### Thá»i gian khá»Ÿi Ä‘á»™ng
- CPU: ~30-60 giÃ¢y
- GPU: ~15-30 giÃ¢y

### Thá»i gian response
- Retrieval: 50-200ms
- Generation: 500-2000ms (CPU) / 100-500ms (GPU)

### Resource usage
- RAM: 4-8GB (tÃ¹y SAMPLE_SIZE)
- GPU VRAM: 4-6GB (náº¿u dÃ¹ng GPU)

## ğŸ”§ Troubleshooting

### Lá»—i: "CUDA out of memory"
```bash
# Trong .env
FORCE_CPU=1
```

### Lá»—i: "Models not loaded"
```bash
# Kiá»ƒm tra káº¿t ná»‘i internet (download models)
# Hoáº·c pre-download models:
python -c "from transformers import AutoModel; AutoModel.from_pretrained('vinai/phobert-base')"
```

### Lá»—i: "Data files not found"
```bash
# Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong config.py
# Äáº£m báº£o QAs.csv vÃ  articles.csv trong thÆ° má»¥c data/
```

## ğŸŒ Web Demo Integration

### React Example

```javascript
const askQuestion = async (query) => {
  const response = await fetch('http://localhost:8000/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, include_sources: true })
  });
  
  const data = await response.json();
  return data;
};
```

### Vue.js Example

```javascript
export default {
  methods: {
    async askQuestion(query) {
      const res = await this.$http.post('/api/chat', {
        query: query,
        include_sources: true
      });
      return res.data;
    }
  }
}
```

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a PR.

## ğŸ“§ Contact

For questions or support, please contact: [your-email]

---

**LÆ°u Ã½:** API nÃ y chá»‰ mang tÃ­nh cháº¥t tham kháº£o, khÃ´ng thay tháº¿ cho tÆ° váº¥n y táº¿ chuyÃªn nghiá»‡p.
